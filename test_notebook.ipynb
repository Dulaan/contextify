{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x31uPc2kdh5P"
      },
      "outputs": [],
      "source": [
        "from pypdf import PdfReader\n",
        "import pymupdf\n",
        "import re\n",
        "import os\n",
        "import requests\n",
        "from serpapi.google_scholar_search import GoogleScholarSearch\n",
        "from groq import Groq\n",
        "from pypdf import PdfReader, PdfWriter\n",
        "from pypdf.annotations import Text\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLxVgSxAgi35"
      },
      "source": [
        "Retrieve references from paper using named destinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewSi-JI0jX1P"
      },
      "outputs": [],
      "source": [
        "def refs_dict(pdf_path):\n",
        "  cites = {}\n",
        "  reader = PdfReader(pdf_path)\n",
        "  doc = pymupdf.open(pdf_path)\n",
        "  height = reader.pages[0].mediabox.height\n",
        "  for cite, info in reader.named_destinations.items():\n",
        "    if cite[:4] == 'cite':\n",
        "        x1 = info['/Left']\n",
        "        y1 = height-info['/Top']\n",
        "        x2 = x1+400\n",
        "        y2 = y1+20\n",
        "        for i in range(len(reader.pages)):\n",
        "          if reader.pages[i] == info['/Page']:\n",
        "            page = doc[i]\n",
        "            rect = pymupdf.Rect(x1,y1,x2,y2)\n",
        "            cites[cite] = page.get_textbox(rect)\n",
        "  return cites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDACIKA3gokP"
      },
      "source": [
        "Create folder to store source files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJFpWmlvzu5G"
      },
      "outputs": [],
      "source": [
        "def make_folder(pdf_path):\n",
        "  title = re.sub(r'\\W+', '', pdf_path)[:-3]\n",
        "  title = f\"{title}_refs\"\n",
        "  if not os.path.exists(title):\n",
        "      os.makedirs(title)\n",
        "  return title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIiwv6yxgu1-"
      },
      "source": [
        "Retrieve documents via Serp API Google Scholar search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2iFGZuQv5W5"
      },
      "outputs": [],
      "source": [
        "def get_doc(folder, title, cite):\n",
        "    api_key = os.environ.get(\"SERP_API_KEY\")\n",
        "    filename = re.sub(r'\\W+', '', cite[5:])\n",
        "\n",
        "    search = GoogleScholarSearch({\"q\": title, \"api_key\":api_key})\n",
        "    data = search.get_dict()\n",
        "    url = data['organic_results'][0]['resources'][0]['link']\n",
        "    r = requests.get(url)\n",
        "\n",
        "    with open(f\"/content/{folder}/{filename}.pdf\", \"wb\") as f:\n",
        "      f.write(r.content)\n",
        "    return f\"{filename}.pdf\"\n",
        "\n",
        "def get_docs(folder, cites):\n",
        "  for cite, title in cites.items():\n",
        "     get_doc(folder, title, cite)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ8P2dTMg0Al"
      },
      "source": [
        "Chunk text to fit in ctx length + Groq rate limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ySnDUxKsUnA"
      },
      "outputs": [],
      "source": [
        "# HELPER FUNCS FOR summarize()\n",
        "\n",
        "def texthalf(text):\n",
        "  return [text[:len(text)//2],text[len(text)//2:]]\n",
        "\n",
        "def text_extractor(file, chunks = 2):\n",
        "    text = \"\"\n",
        "    reader = PdfReader(file)\n",
        "    for page in reader.pages:\n",
        "      text+=page.extract_text()\n",
        "    return re.sub('\\n', ' ', text)\n",
        "\n",
        "def get_chunked(folder, file):\n",
        "    return texthalf(text_extractor(f\"/content/{folder}/{file}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm0_M3q3g5RA"
      },
      "source": [
        "Call Groq Llama 3 70B to summarize the halves of the document then combine the two"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i6NRof2rwqA"
      },
      "outputs": [],
      "source": [
        "def summarize(client, text):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "\n",
        "      messages=[\n",
        "\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": \"\"\"You are a professional summarizer hired by me to provide context to citations within papers. You will be provided with the text\n",
        "              within which the citation appears as well as relevant text chunks from the cited paper. Please use the text chunks to provide context for the citation.\n",
        "              Make your explanation as brief as possible while still fully explaining the citation's relevance to the passage.\n",
        "              \"\"\"\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": text,\n",
        "          }\n",
        "      ],\n",
        "      model=\"llama3-70b-8192\",\n",
        "      temperature=0.5,\n",
        "      max_tokens=1024,\n",
        "      top_p=1,\n",
        "      stop=None,\n",
        "      stream=False,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "def final(texts, ctx):\n",
        "  return f\"\"\"Explain the following passage:\n",
        "\"{texts}\"\n",
        "using this context from the paper cited: \"{ctx}\". CONTEXTUALIZE: \"\"\"\n",
        "\n",
        "def summarize_paper(client, text, ref_ctx):\n",
        "  inputs = final(text, ref_ctx)\n",
        "  return summarize(client, inputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA68iwOUj3u5"
      },
      "source": [
        "Match citation summaries to citation locations,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ND9PcS_SftL"
      },
      "outputs": [],
      "source": [
        "def locs_dict(pdf_path, cites):\n",
        "  reader = PdfReader(pdf_path)\n",
        "  locs = {cite: {} for cite in cites}\n",
        "  for page_num, page in enumerate(reader.pages):\n",
        "      if '/Annots' in page:\n",
        "          for annot in page['/Annots']:\n",
        "              obj = annot.get_object()\n",
        "              if '/Subtype' in obj and obj['/Subtype'] == '/Link' and '/A' in obj and obj['/A']['/S'] == '/GoTo':\n",
        "                  cite_ref = obj['/A']['/D']\n",
        "                  if cite_ref in locs.keys():\n",
        "                    if not locs[cite_ref]:\n",
        "                      locs[cite_ref] = {page_num:[obj['/Rect']]}\n",
        "                    elif page_num not in locs[cite_ref].keys():\n",
        "                      locs[cite_ref][page_num] = [obj['/Rect']]\n",
        "                    else:\n",
        "                      locs[cite_ref][page_num].append(obj['/Rect'])\n",
        "  return locs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXFOfQhZU9OU"
      },
      "source": [
        "get surrounding context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOipn82fU_AD"
      },
      "outputs": [],
      "source": [
        "def get_ctx(doc, reader, cite):\n",
        "  ctx = {}\n",
        "  for page_num, page in enumerate(reader.pages):\n",
        "    if '/Annots' in page:\n",
        "        for annot in page['/Annots']:\n",
        "            obj = annot.get_object()\n",
        "            if '/Subtype' in obj and obj['/Subtype'] == '/Link' and '/A' in obj and obj['/A']['/S'] == '/GoTo':\n",
        "                cite_ref = obj['/A']['/D']\n",
        "                if cite_ref in cite:\n",
        "                  info = obj['/Rect']\n",
        "                  x1 = 100\n",
        "                  y1 = 792-info[1]-10\n",
        "                  x2 = 500\n",
        "                  y2 = y1+25\n",
        "                  rect = pymupdf.Rect(x1,y1,x2,y2)\n",
        "                  if page_num not in ctx.keys():\n",
        "                    ctx[page_num] = [re.sub('\\n', ' ', doc[page_num].get_textbox(rect))]\n",
        "                  else:\n",
        "                    ctx[page_num].append(re.sub('\\n', ' ', doc[page_num].get_textbox(rect)))\n",
        "  return ctx\n",
        "\n",
        "\n",
        "def ctx_dict(pdf_path, cites):\n",
        "  doc = pymupdf.open(pdf_path)\n",
        "  reader = PdfReader(pdf_path)\n",
        "  cite_dict = {}\n",
        "  for cite in cites:\n",
        "    cite_dict[cite] = get_ctx(doc, reader, cite)\n",
        "  return cite_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjaOgbKofk8m"
      },
      "outputs": [],
      "source": [
        "def init_rag(folder):\n",
        "    docs = []\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=400, chunk_overlap=50, separator = \" \")\n",
        "    for file in os.listdir(folder):\n",
        "        text = text_extractor(folder+\"/\"+file)\n",
        "        docs.append(text)\n",
        "    texts = text_splitter.create_documents(docs)\n",
        "    embeddings = HuggingFaceEmbeddings()\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "    retreiver = db.as_retriever()\n",
        "    return retreiver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw3OmIAgk8FQ"
      },
      "outputs": [],
      "source": [
        "def summaries_dict(folder_path, ctx):\n",
        "  key = os.environ.get(\"GROQ_API_KEY\")\n",
        "  client = Groq(api_key = key)\n",
        "  summ = {}\n",
        "  index = init_rag(folder_path)\n",
        "  for cite, ctxs in ctx.items():\n",
        "    summ[cite] = {}\n",
        "    for page, ctx in ctxs.items():\n",
        "      summ[cite][page] = []\n",
        "      for c in ctx:\n",
        "        docs = index.get_relevant_documents(c, k = 2)\n",
        "        info = str([doc.page_content for doc in docs])\n",
        "        summary = summarize_paper(client, c, info)\n",
        "        print(summary)\n",
        "        summ[cite][page].append(summary)\n",
        "  return summ\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xrTlYuNhHZy"
      },
      "source": [
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etHSnfpgOyCv",
        "outputId": "553b2651-6a26-4662-d81e-c32de0c9cb10"
      },
      "outputs": [],
      "source": [
        "def add_popup_annotation(writer, page_number, rect, content):\n",
        "    annotation = Text(text = content, rect = rect)\n",
        "    writer.add_annotation(page_number=page_number, annotation=annotation)\n",
        "\n",
        "def annotations(p, c, l, s):\n",
        "  reader = PdfReader(p)\n",
        "  writer = PdfWriter()\n",
        "  for page in reader.pages:\n",
        "    writer.add_page(page)\n",
        "  for cite in c.keys():\n",
        "    for page, coords in l[cite].items():\n",
        "      for i in range(len(coords)):\n",
        "        add_popup_annotation(writer, page, coords[i], re.sub('\\n', '', s[cite][page][i]))\n",
        "  with open(\"annotated.pdf\", \"wb\") as fp:\n",
        "      writer.write(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Fmb8YqOrDh-",
        "outputId": "2f4c9526-86b5-4e79-acc5-3b7f3379ec40"
      },
      "outputs": [],
      "source": [
        "os.getenv(\"GROQ_KEY\") = input(\"Groq API Key\")\n",
        "os.getenv(\"SERP_KEY\") = input(\"Serp API Key\")\n",
        "\n",
        "pdf_path = \"1706.03762v7.pdf\"\n",
        "\n",
        "folder_path = make_folder(pdf_path)\n",
        "\n",
        "refs = refs_dict(pdf_path)\n",
        "\n",
        "#test with one\n",
        "cite, title = list(refs.items())[0]\n",
        "refs = {cite:title}\n",
        "\n",
        "get_docs(folder_path, refs)\n",
        "\n",
        "locs = locs_dict(pdf_path, refs.keys())\n",
        "\n",
        "ctx = ctx_dict(pdf_path, refs.keys())\n",
        "\n",
        "sum = summaries_dict(folder_path, ctx)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
